{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Get me a flight to JFK\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "mytext = 'Good Morning. I need to fly to New York and say over in London.\\\n",
    "           Get me a flight to JFK and a hotel in central London'\n",
    "\n",
    "language = 'en'\n",
    "\n",
    "tts = gTTS(text=mytext, lang=language) \n",
    "\n",
    "tts.save('flight.mp3')\n",
    "\n",
    "os.system(\"mpg321 flight.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to wav file \n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "# files                                                                         \n",
    "src = \"flight.mp3\"\n",
    "dst = \"flight.wav\"\n",
    "\n",
    "# convert wav to mp3                                                            \n",
    "sound = AudioSegment.from_mp3(src)\n",
    "\n",
    "sound.export(dst, format=\"wav\")\n",
    "play(sound)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcribing Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.WavFile('flight.wav') as source:\n",
    "     audio = r.record(source)  # read the entire audio file \n",
    "     print(\"Transcription: \" + r.recognize_google(audio, language='en-US'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "sentence = \"Get me a flight to JFK\"\n",
    "\n",
    "tokens = word_tokenize(sentence)\n",
    "tagged_tokens = pos_tag(tokens)\n",
    "print(tagged_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What can go wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk, pos_tag, word_tokenize\n",
    "utterance = (\"Get me a flight to JFK\")\n",
    "tree = ne_chunk(pos_tag(word_tokenize(utterance)))\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print dependency parsing tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import Tree\n",
    "from nltk.draw.util import CanvasFrame\n",
    "from nltk.draw import TreeWidget\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "\n",
    "grammar = \"NP: {<DT>?<JJ>*<NN>}\"\n",
    "parser = nltk.RegexpParser(grammar)\n",
    "result = parser.parse(tree)\n",
    "\n",
    "cf = CanvasFrame()\n",
    "tc = TreeWidget(cf.canvas(),result)\n",
    "cf.add_widget(tc,10,10) # (10,10) offsets\n",
    "cf.print_to_file('tree.ps')\n",
    "cf.destroy()\n",
    "\n",
    "! convert tree.ps tree.png\n",
    "! rm tree.ps\n",
    "image = Image(filename='tree.png')\n",
    "display(image)\n",
    "! rm tree.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic ambiguity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterance = (\"Get me a flight to John F Kennedy\")\n",
    "print(ne_chunk(pos_tag(word_tokenize(utterance))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib\n",
    "\n",
    "query = \"JFK\"\n",
    "api_key = open('.api_key').read()\n",
    "service_url = 'https://kgsearch.googleapis.com/v1/entities:search'\n",
    "params = {\n",
    "    'query': query,\n",
    "    'limit': 10,\n",
    "    'indent': True,\n",
    "    'key': api_key,\n",
    "}\n",
    "url = service_url + '?' + urllib.parse.urlencode(params)\n",
    "response = json.loads(urllib.request.urlopen(url).read())\n",
    "\n",
    "for element in response['itemListElement']: \n",
    "    if 'result' in element and 'name' in element['result']:\n",
    "        print(element['result']['name'] + ' (' + str(element['resultScore']) + ')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
